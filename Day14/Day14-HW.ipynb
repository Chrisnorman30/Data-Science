{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ce44393-3036-4c90-904f-1e85718f57fb",
   "metadata": {},
   "source": [
    "## Introduction to Data Science\n",
    "\n",
    "#### University of Redlands - DATA 101\n",
    "#### Prof: Joanna Bieri [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "#### [Class Website: data101.joannabieri.com](https://joannabieri.com/data101.html)\n",
    "\n",
    "---------------------------------------\n",
    "# Homework Day 14\n",
    "---------------------------------------\n",
    "\n",
    "GOALS:\n",
    "\n",
    "1. Reflect on Algorithmic bias\n",
    "2. Consider your role in Data Ethics\n",
    "3. Report on your reading.\n",
    "\n",
    "----------------------------------------------------------\n",
    "\n",
    "This homework has **3 questions** and **1 reading report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0c422e3-32b1-452f-89a8-2586784d3957",
   "metadata": {},
   "source": [
    "## Important Information\n",
    "\n",
    "- Email: [joanna_bieri@redlands.edu](mailto:joanna_bieri@redlands.edu)\n",
    "- Office Hours: Duke 209 <a href=\"https://joannabieri.com/schedule.html\"> Click Here for Joanna's Schedule</a>\n",
    "\n",
    "## If you start having trouble with git!!!\n",
    "\n",
    "Some people have reported that GIT is disappearing or giving errors on when they try to use it in Jupyter Lab. Here is another option for interacting with git:\n",
    "\n",
    "[Git Desktop](https://github.com/apps/desktop)\n",
    "\n",
    "If yous start having errors, try downloading this app. I can show you how to use it in class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15fd0fc5-0e82-4265-a328-e906366c4907",
   "metadata": {},
   "source": [
    "## Report on your Data Ethics reading:\n",
    "\n",
    "**Your answers should be written as neatly as possible in Markdown cells**\n",
    "\n",
    "Your homework for today is all essay and written work. Make sure you respond to the three questions in the lecture:\n",
    "\n",
    "**Q1** What is your response to our discussion of bias in algorithms? Talk about the pluses and minuses of using algorithms to make decisions in our human world.\n",
    "\n",
    "I think algorithms can be really helpful because they can process huge amounts of information quickly and make decisions that are consistent and efficient. They can remove some types of human error or emotion from decision-making. But the downside is that algorithms can also carry hidden biases from the data they’re trained on, which can lead to unfair results—especially in areas like hiring, policing, or lending. If the data reflects inequality, the algorithm might repeat or even worsen it. So while algorithms can make life easier, we have to be careful, test them often, and make sure people still have oversight to keep decisions fair.\n",
    "\n",
    "**Q2**\n",
    "How do you train yourself to make the right decisions (or reduce the likelihood of accidentally making the wrong decisions) at those points?\n",
    "\n",
    "I try to slow down and think carefully before making important decisions, especially when they affect other people. I make sure to look at all the information I have, question my own assumptions, and consider different perspectives. When I’m unsure, I ask for advice or double-check my reasoning instead of rushing. I also try to learn from past mistakes so I can recognize warning signs next time. Taking time to reflect and being open to feedback helps me make more thoughtful, fair, and accurate choices.\n",
    "\n",
    "**Q3**\n",
    "How do you respond when you see bias in someones work? How could you take action to educate others?\n",
    "\n",
    "When I see bias in someone’s work, I try to approach it calmly and respectfully. I point out what seems biased and explain why it might lead to unfair or inaccurate results. Instead of blaming, I focus on helping the person understand how the bias could affect their conclusions. To educate others, I could share examples, talk about how bias shows up in data or decisions, and show ways to check for it. Encouraging open discussion and teaching people to question their assumptions can help everyone become more aware and fair in their work.\n",
    "\n",
    "\n",
    "**Reading Report**\n",
    "\n",
    "Write a report about what you learned from your ethics reading exploration. For each book/article you read:\n",
    "\n",
    "1. Include a full proper reference to the book/article.\n",
    "   * BOOK: Author last name, First name. Book Title: Subtitle. Edition, Publisher, Year.\n",
    "   * ONLINE ARTICLE: Author last name, First name. Article Title. Website name, date accessed. html link.\n",
    "   * [MLA styles for citing other types of online work](https://style.mla.org/works-cited/citations-by-format/online-works/?gad_source=1)\n",
    "2. Write a summary in your own words what the book/article was about. Imagine telling your classmates about what they would learn by reading the article.\n",
    "3. Discuss your own reaction to the book/article. Did it have any effect on how you think about data and ethics? Do you agree with the author? What specific ideas really stood out to you?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf53176f-7926-4d4e-967c-5b5bbd011abe",
   "metadata": {},
   "source": [
    "**Q1** \n",
    "O’Neil, Cathy. Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy. Crown, 2016.\n",
    "\n",
    "In this book, O’Neil explains how algorithms can create unfair outcomes when they are used to make decisions about people’s lives, such as in hiring, policing, and education. I learned that data is not always neutral—if the data reflects inequality, the algorithm will too. The main lesson I took away is that we need transparency and accountability when using data-driven systems to make sure they don’t harm vulnerable groups."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a527f22-684c-4aee-aa4d-afd435a9c996",
   "metadata": {},
   "source": [
    "Q2 This book talks about how algorithms and big data can sometimes do more harm than good. O’Neil explains that computer programs used in jobs, schools, and even the justice system can be unfair if they use bad or biased data. By reading this book, you’ll learn how technology can quietly create inequality and why it’s important to question how data is used to make decisions about people.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7335bfa0-82c0-46d7-9734-f4300dedfa54",
   "metadata": {},
   "source": [
    "**Q3**\n",
    "Reading these works really made me think differently about how data and technology affect people’s lives. I used to think algorithms were mostly objective, but now I see how easily bias can slip in when the data itself is unfair. I agree with the authors that we need to be more careful and transparent when creating and using data systems. What stood out to me most was Cathy O’Neil’s idea that “mathematical models can be just as biased as the people who build them.” That made me realize that data ethics isn’t just about numbers—it’s about people and fairness. These readings reminded me that technology should always serve humanity, not the other way around.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca89bb8-e1ea-4af6-aea6-faf8874deaf2",
   "metadata": {},
   "source": [
    "**Reading Report**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6faae4b-ce39-4695-a87f-99e40bda1322",
   "metadata": {},
   "source": [
    "\n",
    "-------------------------------------------------------\n",
    "\n",
    "## Further watching\n",
    "\n",
    "If you have time, really explore the world of data ethics. You could watch some of the videos linked from class.\n",
    "\n",
    "### Weapons of Math Destruction | Cathy O'Neil | Talks at Google\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=TQHs8SA1qpk >}}\n",
    "\n",
    "### Imagining a Future Free from the Algorithms of Oppression | Safiya Noble | ACL 2019\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=tNi_U1Bb1S0 >}}\n",
    "\n",
    "### Whats An Algorithm Got To Do With It\n",
    "\n",
    "{{< video https://www.youtube.com/watch?v=5zxDwA99soA >}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75adfae-6e62-4549-9856-bf7030620521",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
